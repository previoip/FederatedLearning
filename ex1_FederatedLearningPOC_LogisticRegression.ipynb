{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Federated Learning - Automobile Dataset Example\n",
        "\n",
        "[Link to dataset source](https://archive.ics.uci.edu/dataset/10/automobile)\n",
        "\n",
        "[Link to Colab (deprecated)](https://colab.research.google.com/drive/1GmAhxnKVvrhWffospDEe0rc-QB_tjfhE?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import logging\n",
        "import warnings\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tensorflow import convert_to_tensor\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from src.tf_utils import df_to_tfds\n",
        "from src.data_examples.ex1_data_loader import ExampleDataLoader\n",
        "from src.data_examples.ex1_build import eval_example_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "RAND_SEED = 1337\n",
        "random.seed(RAND_SEED)\n",
        "\n",
        "saved_model_path = Path('saved_models')\n",
        "saved_model_path.mkdir(exist_ok=True)\n",
        "metrics_csv_path = Path('metrics')\n",
        "metrics_csv_path.mkdir(exist_ok=True)\n",
        "\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_histories = {}\n",
        "result_models = {}\n",
        "result_rmse = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached file cache\\static\\public\\10\\automobile.zip\n",
            "extracting zip file content:\n",
            " \tsize: 144\tfilename: Index\n",
            " \tsize: 1197\tfilename: app.css\n",
            " \tsize: 25936\tfilename: imports-85.data\n",
            " \tsize: 4747\tfilename: imports-85.names\n",
            " \tsize: 3757\tfilename: misc\n"
          ]
        }
      ],
      "source": [
        "data = ExampleDataLoader()\n",
        "data.download().load().clean()\n",
        "\n",
        "data.df['symboling_threshold'] = [1 if i > 0 else 0 for i in data.df['symboling']]\n",
        "\n",
        "target_feature_label = 'symboling_threshold'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_random_sample_from_spec(data_spec, features_override=[]):\n",
        "  ret = {}\n",
        "  for k in data_spec.keys():\n",
        "    if features_override and k not in features_override:\n",
        "      continue\n",
        "    v = data_spec.get(k)\n",
        "    if isinstance(v, tuple):\n",
        "      ret[k] = random.random() * (v[1] - v[0])\n",
        "    elif isinstance(v, list):\n",
        "      ret[k] = random.choice(v)\n",
        "    else:\n",
        "      ret[k] = v\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "__inference_sample_spec = list(map(lambda x: x.replace('_', '-'), data.features_categorical + data.features_numeric_continuous))\n",
        "__inference_sample = generate_random_sample_from_spec(data.data_spec, __inference_sample_spec)\n",
        "inference_sample = {}\n",
        "for k, v in __inference_sample.items():\n",
        "  inference_sample[k.replace('-', '_')] = convert_to_tensor([v])\n",
        "\n",
        "inference_sample"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Centralized (Conventional) Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epoch = 50\n",
        "batch_size = 24\n",
        "\n",
        "model_name = 'ex1ch1_auto_classifier_centralized'\n",
        "\n",
        "ex1ch1_model_path = saved_model_path / model_name\n",
        "\n",
        "result_histories[model_name] = []\n",
        "result_models[model_name] = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((127, 27), (16, 27), (16, 27))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train    = data.df.sample(frac=0.8, random_state=RAND_SEED)\n",
        "df_val_test = data.df.drop(df_train.index)\n",
        "df_test     = df_val_test.sample(frac=0.5, random_state=RAND_SEED)\n",
        "df_val      = df_val_test.drop(df_test.index)\n",
        "\n",
        "tfds_train  = df_to_tfds(df_train, target_feature_label, batch_size=batch_size)\n",
        "tfds_test   = df_to_tfds(df_test,  target_feature_label, batch_size=batch_size)\n",
        "tfds_val    = df_to_tfds(df_val,   target_feature_label, batch_size=batch_size)\n",
        "\n",
        "df_train.shape, df_test.shape, df_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logging to ex1ch1_auto_classifier_centralized_metrics.csv\n"
          ]
        }
      ],
      "source": [
        "res_model, logger, history = eval_example_data(\n",
        "    tfds_train,\n",
        "    tfds_val,\n",
        "    data,\n",
        "    epoch=n_epoch,\n",
        "    model_name=model_name\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1371 - accuracy: 0.9375 - mse: 0.3150\n",
            "Loss: 0.1370590329170227 Accuracy: 0.9375 MSE: 0.3150026798248291\n"
          ]
        }
      ],
      "source": [
        "res_model.save(ex1ch1_model_path)\n",
        "result_histories[model_name].append(history)\n",
        "result_models[model_name].append(res_model)\n",
        "\n",
        "loss, accuracy, mse = res_model.evaluate(tfds_test)\n",
        "print(\n",
        "  'Loss:', loss,\n",
        "  'Accuracy:', accuracy,\n",
        "  'MSE:', mse\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Federated Model - Model Ensembling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_client = 5\n",
        "n_epoch = 50\n",
        "batch_size = 24\n",
        "\n",
        "model_name = 'ex1ch1_auto_classifier_federated_model_ensemble'\n",
        "\n",
        "ex1ch2_model_path = saved_model_path / model_name\n",
        "\n",
        "result_histories[model_name] = []\n",
        "result_models[model_name] = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logging to ex1ch1_auto_classifier_federated_model_ensemble_0_metrics.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0505 - accuracy: 1.0000 - mse: 0.0527\n",
            "logging to ex1ch1_auto_classifier_federated_model_ensemble_1_metrics.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2115 - accuracy: 1.0000 - mse: 0.0415\n",
            "logging to ex1ch1_auto_classifier_federated_model_ensemble_2_metrics.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0448 - accuracy: 1.0000 - mse: 0.2262\n",
            "logging to ex1ch1_auto_classifier_federated_model_ensemble_3_metrics.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0838 - accuracy: 1.0000 - mse: 0.1423\n",
            "logging to ex1ch1_auto_classifier_federated_model_ensemble_4_metrics.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1704 - accuracy: 1.0000 - mse: 0.4542\n",
            "ex1ch1_auto_classifier_federated_model_ensemble - 0Loss: 0.050481170415878296 Accuracy: 1.0 MSE: 0.05273614823818207\n",
            "ex1ch1_auto_classifier_federated_model_ensemble - 1Loss: 0.21150441467761993 Accuracy: 1.0 MSE: 0.04154187813401222\n",
            "ex1ch1_auto_classifier_federated_model_ensemble - 2Loss: 0.044761817902326584 Accuracy: 1.0 MSE: 0.2261928915977478\n",
            "ex1ch1_auto_classifier_federated_model_ensemble - 3Loss: 0.08383435010910034 Accuracy: 1.0 MSE: 0.14228679239749908\n",
            "ex1ch1_auto_classifier_federated_model_ensemble - 4Loss: 0.17041529715061188 Accuracy: 1.0 MSE: 0.45423534512519836\n"
          ]
        }
      ],
      "source": [
        "__metrics = []\n",
        "\n",
        "for n, data_df in enumerate(np.array_split(data.df, n_client)):\n",
        "\n",
        "  client_model_name = f'{model_name}_{n}'\n",
        "  ex1ch2_model_path_c = saved_model_path / client_model_name \n",
        "\n",
        "  df_train    = data_df.sample(frac=0.8, random_state=RAND_SEED)\n",
        "  df_val_test = data_df.drop(df_train.index)\n",
        "  df_test     = df_val_test.sample(frac=0.5, random_state=RAND_SEED)\n",
        "  df_val      = df_val_test.drop(df_test.index)\n",
        "\n",
        "  _tfds_train  = df_to_tfds(df_train, target_feature_label, batch_size=batch_size)\n",
        "  _tfds_test   = df_to_tfds(df_test,  target_feature_label, batch_size=batch_size)\n",
        "  _tfds_val    = df_to_tfds(df_val,   target_feature_label, batch_size=batch_size)\n",
        "\n",
        "  res_model, logger, history = eval_example_data(\n",
        "    _tfds_train,\n",
        "    _tfds_val,\n",
        "    data,\n",
        "    epoch=n_epoch,\n",
        "    model_name=client_model_name\n",
        "  )\n",
        "\n",
        "  res_model.save(ex1ch2_model_path_c)\n",
        "  result_histories[model_name].append(history)\n",
        "  result_models[model_name].append(res_model)\n",
        "\n",
        "  __metrics.append(res_model.evaluate(_tfds_test))\n",
        "\n",
        "\n",
        "for n, (loss, accuracy, mse)  in enumerate(__metrics):\n",
        "  print(\n",
        "    f'{model_name} - {n}'\n",
        "    'Loss:', loss,\n",
        "    'Accuracy:', accuracy,\n",
        "    'MSE:', mse\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_3')>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_models[model_name][0].outputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4527 - accuracy: 0.7500 - mse: 0.3912\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.2040 - accuracy: 0.6875 - mse: 1.3808\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.1778 - accuracy: 0.8125 - mse: 0.8154\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3373 - accuracy: 0.8125 - mse: 0.6318\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2105 - accuracy: 0.6875 - mse: 1.8657\n",
            "Loss: 1.6764457821846008 Accuracy: 0.75 MSE: 1.0169736981391906\n"
          ]
        }
      ],
      "source": [
        "def fn_eval(model, tfds):\n",
        "  return model.evaluate(tfds)\n",
        "\n",
        "def fn_predict(model, tfds):\n",
        "  return model.predict(tfds)\n",
        "\n",
        "def evaluate_ensemble(models, tfds, fn):\n",
        "  res = []\n",
        "  for model in models:\n",
        "    res.append(fn(model, tfds))\n",
        "  return np.mean(res, axis=0)\n",
        "\n",
        "# loss, accuracy, mse = stacked_model.evaluate(tfds_test)\n",
        "loss, accuracy, mse = evaluate_ensemble(result_models[model_name], tfds_test, fn_eval)\n",
        "\n",
        "print(\n",
        "  'Loss:', loss,\n",
        "  'Accuracy:', accuracy,\n",
        "  'MSE:', mse\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- perbandingan conventional/federated\n",
        "- data distrib: 1-1, weighted sum\n",
        "-  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "hist = result_histories['ex1ch1_auto_classifier_federated_naive'][1]\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title(f'Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
